{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "  print('Running on CoLab')\n",
    "  %matplotlib inline\n",
    "else:\n",
    "    print('Not running on CoLab')\n",
    "    %matplotlib notebook\n",
    "    import os\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2e97eb7cabcc0430",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import scipy as sp\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, GRU, Conv2D, Flatten, MaxPooling2D, Dropout, Reshape, TimeDistributed\n",
    "from IPython.display import HTML\n",
    "from funtion_file import matrix_maker\n",
    "\n",
    "class MatrixMaker:\n",
    "    __slots__ = (\"rows\", \"cols\", \"kernel_size\", \"line_size\", 'num_per_mat', 'smooth_matrix', 'line_start_position', 'alfa', 'matrix_fade', 'line_pos_mat')\n",
    "    def __init__(self, rows, cols=None, kernel_size=(1, 1), line_size=(1, 2), num_per_mat=10):\n",
    "        self.rows = rows\n",
    "        self.cols = cols or rows\n",
    "        self.kernel_size = kernel_size\n",
    "        self.line_size = line_size\n",
    "        self.num_per_mat = num_per_mat\n",
    "\n",
    "        self.smooth_matrix = self.create_smoothed_matrix()\n",
    "        self.line_start_position = self.create_line_start_position()\n",
    "        self.alfa = self.create_alfa()\n",
    "        self.matrix_fade = self.create_matrix_line_fade()\n",
    "        self.line_pos_mat = self.create_line_pos_mat()\n",
    "\n",
    "    def create_smoothed_matrix(self):\n",
    "        kernel = np.ones(shape=self.kernel_size, dtype=float) / (self.kernel_size[0] * self.kernel_size[1])\n",
    "        return sp.ndimage.convolve(np.random.rand(self.rows, self.cols), kernel)\n",
    "\n",
    "    def create_line_start_position(self):\n",
    "        return (np.random.randint(low=0, high=self.rows - self.line_size[0] + 1),\n",
    "                np.random.randint(low=0, high=self.cols - self.line_size[1] + 1))\n",
    "\n",
    "    def create_alfa(self):\n",
    "        return np.linspace(1, 0, num=self.num_per_mat)\n",
    "\n",
    "    def create_matrix_with_line(self, alfa):\n",
    "        matrix = np.ones((self.rows, self.cols))\n",
    "        matrix[self.line_start_position[0]:self.line_start_position[0] + self.line_size[0],\n",
    "        self.line_start_position[1]:self.line_start_position[1] + self.line_size[1]] = alfa\n",
    "        return matrix\n",
    "\n",
    "    def create_matrix_line_fade(self):\n",
    "        matrix_line_fade = []\n",
    "        for i in range(self.num_per_mat):\n",
    "            line = self.create_matrix_with_line(self.alfa[i])\n",
    "            matrix_line_fade.append(self.smooth_matrix * line)\n",
    "\n",
    "        return matrix_line_fade\n",
    "\n",
    "    def create_line_pos_mat(self):\n",
    "        return np.array(np.logical_not(self.create_matrix_with_line(0)).astype(int), dtype='float16')\n",
    "\n",
    "\n",
    "class MatrixLister:\n",
    "    def __init__(self, row_len, col_len, kernel_size, min_max_line_size, rotate, num_of_mat, num_per_mat, num_neuron):\n",
    "        self.row_len = row_len\n",
    "        self.col_len = col_len\n",
    "        self.kernel_size = kernel_size\n",
    "        self.min_max_line_size = min_max_line_size\n",
    "        self.rotate = rotate\n",
    "        self.num_of_mat = num_of_mat\n",
    "        self.num_per_mat = num_per_mat\n",
    "        self.num_neuron = num_of_neurons\n",
    "\n",
    "        self.matrix_list = self.create_matrix_in_list()\n",
    "        self.con_matrix, self.con_alfa = self.concatenate_matrices()\n",
    "\n",
    "        self.neural_network = NeuralNetwork(input_size=(row_len, col_len), num_neuron=self.num_neuron)\n",
    "\n",
    "    def create_matrix_in_list(self):\n",
    "        line_sizes = [rotater((np.random.randint(self.min_max_line_size[0][0], self.min_max_line_size[1][0] + 1),\n",
    "                       np.random.randint(self.min_max_line_size[0][1], self.min_max_line_size[1][1] + 1)))\n",
    "                      for _ in range(self.num_of_mat)]\n",
    "\n",
    "        return [MatrixMaker(self.row_len, self.col_len, self.kernel_size, line_sizes[i], self.num_per_mat)\n",
    "                for i in range(self.num_of_mat)]\n",
    "\n",
    "    def concatenate_matrices(self):\n",
    "        concatenated_matrices = []\n",
    "        con_alfa = []\n",
    "\n",
    "        for matrix in self.matrix_list:\n",
    "            concatenated_matrices += matrix.create_matrix_line_fade()\n",
    "            con_alfa += list(matrix.alfa)\n",
    "\n",
    "        return np.array(concatenated_matrices, dtype='float32'), con_alfa\n",
    "\n",
    "    def con_line_pos_mat(self):\n",
    "        con_line_pos_mat = []\n",
    "        for matrix in self.matrix_list:\n",
    "            for alfa in matrix.alfa:\n",
    "                if alfa != 1:\n",
    "                    con_line_pos_mat.append(matrix.line_pos_mat)\n",
    "                else:\n",
    "                    con_line_pos_mat.append(np.zeros((self.row_len, self.col_len)))\n",
    "                    \n",
    "                    \n",
    "        fisk = np.stack(con_line_pos_mat)\n",
    "        return fisk\n",
    "    \n",
    "    def make_new_matrix_in_list(self, **kwargs):\n",
    "        update = False\n",
    "        for key, value in kwargs.items():\n",
    "            if key in ['row_len', 'col_len']:\n",
    "                update = True\n",
    "            if hasattr(self, key):\n",
    "                setattr(self, key, value)\n",
    "            else:\n",
    "                print(f\"Attribute {key} does not exist in the class.\")\n",
    "        \n",
    "        self.matrix_list = self.create_matrix_in_list()\n",
    "        self.con_matrix, self.con_alfa = self.concatenate_matrices()\n",
    "        if update:\n",
    "            self.neural_network = NeuralNetwork(input_size=(row_len, col_len), num_neuron=self.num_neuron)\n",
    "\n",
    "    def train_neural_network(self, num_epochs=10, batch_size=64):\n",
    "\n",
    "        self.neural_network.train(self.con_matrix, self.con_line_pos_mat(), num_epochs, batch_size)\n",
    "\n",
    "    def plot(self, interval=200):\n",
    "        fig, ax = plt.subplots()\n",
    "\n",
    "        def update(frame):\n",
    "            ax.clear()\n",
    "            im = ax.imshow(self.con_matrix[frame], interpolation='nearest', aspect='auto', vmin=0, vmax=1)\n",
    "\n",
    "            return [im]\n",
    "\n",
    "        animation = FuncAnimation(fig, update, frames=len(self.con_matrix), interval=interval, repeat=False, blit=True)\n",
    "        plt.tight_layout()\n",
    "        plt.show(block=False)\n",
    "        plt.show()\n",
    "        return animation\n",
    "    \n",
    "    def plot_matrices(self, num_to_pred, new_mat=False, interval=500):\n",
    "        if new_mat:\n",
    "            self.num_of_mat = num_to_pred\n",
    "            self.matrix_list = self.create_matrix_in_list()\n",
    "            self.con_matrix, self.con_alfa = self.concatenate_matrices()\n",
    "            \n",
    "        input_matrix = np.array(self.con_matrix[:num_to_pred*self.num_per_mat])\n",
    "        true_matrix = np.array(self.con_line_pos_mat())\n",
    "        pred = self.neural_network.predict(input_matrix)\n",
    "    \n",
    "        predicted_line_pos_mat = np.array(pred).reshape(input_matrix.shape)\n",
    "        \n",
    "        fig, axes = plt.subplots(1, 3, figsize=(12, 4))  # 1 row, 3 columns\n",
    "    \n",
    "        def update(frame):\n",
    "            # Plot Input Matrix\n",
    "            im = [axes[0].imshow(input_matrix[frame], interpolation='nearest', aspect='auto', vmin=0, vmax=1)]\n",
    "            axes[0].set_title('Input Matrix')\n",
    "    \n",
    "            # Plot True Line Position Matrix\n",
    "            im.append(axes[1].imshow(true_matrix[frame], interpolation='nearest', aspect='auto', vmin=0, vmax=1))\n",
    "            axes[1].set_title('True Line Position Matrix')\n",
    "    \n",
    "            # Plot Predicted Line Position Matrix\n",
    "            im.append(axes[2].imshow(predicted_line_pos_mat[frame], interpolation='nearest', aspect='auto', vmin=0, vmax=1))\n",
    "            axes[2].set_title('Predicted Line Position Matrix')\n",
    "            \n",
    "            return im\n",
    "    \n",
    "        animation = FuncAnimation(fig, update, frames=len(input_matrix), interval=interval, repeat=False, blit=True)\n",
    "    \n",
    "        plt.tight_layout()\n",
    "        plt.show(block=False)\n",
    "        return animation\n",
    "\n",
    "\n",
    "def rotater(line):\n",
    "    if np.random.random() < 0.5:\n",
    "        return line[::-1]\n",
    "    return line\n",
    "\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, input_size, num_neuron):\n",
    "        self.fh = None \n",
    "        self.model = self.build_model(input_size, num_neuron)\n",
    "\n",
    "    def build_model(self, input_size, num_neuron):\n",
    "        model = Sequential()\n",
    "        \n",
    "        # Apply Conv2D and Flatten to each time step\n",
    "        model.add(Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "        model.add(Conv2D(64, kernel_size=(2, 2), padding='same', activation='relu'))\n",
    "        model.add(MaxPooling2D(pool_size=2))\n",
    "        model.add(Conv2D(128, kernel_size=(2, 2), padding='same', activation='relu'))\n",
    "        model.add(MaxPooling2D(pool_size=2))\n",
    "        # Apply SimpleRNN to the output of Conv2D and Flatten\n",
    "        model.add(TimeDistributed(Flatten()))\n",
    "        model.add(GRU(num_neuron, activation='tanh', return_sequences=True))\n",
    "        model.add(Dropout(0.1))\n",
    "        model.add(GRU(num_neuron, activation='tanh'))\n",
    "        \n",
    "        # Fully connected layer\n",
    "        model.add(Dense(input_size[0] * input_size[1], activation='sigmoid'))\n",
    "        \n",
    "        # Reshape to the desired output shape\n",
    "        model.add(Reshape((input_size[0], input_size[1], 1)))\n",
    "        \n",
    "        model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['F1_Score'])\n",
    "        return model\n",
    "\n",
    "    def train(self, input_data, output_data, epochs, batch_size):\n",
    "        in_data = np.expand_dims(input_data, -1)\n",
    "        out_data = np.expand_dims(output_data, -1)\n",
    "\n",
    "        self.model.fit(in_data, out_data, epochs=epochs, batch_size=batch_size)\n",
    "\n",
    "    def predict(self, input_matrices):\n",
    "        # Flatten and concatenate all input matrices in the batch\n",
    "        input_data = np.expand_dims(np.array([matrix for matrix in input_matrices]),-1)\n",
    "    \n",
    "        # Predict the output for the entire batch\n",
    "        predicted_output = self.model.predict(input_data)\n",
    "    \n",
    "        return predicted_output\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-17T13:15:12.672870Z",
     "start_time": "2024-01-17T13:15:12.667500200Z"
    }
   },
   "id": "e60586cf65efb97b",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "row_len = 10\n",
    "col_len = 12\n",
    "kernel_size = (3, 3)\n",
    "min_max_line_size = [(1,4),(2,5)]\n",
    "rotate = True\n",
    "num_of_mat = 500\n",
    "numb_of_picture = 8\n",
    "num_of_neurons = 256\n",
    "\n",
    "matrix_lister = MatrixLister(row_len, col_len, kernel_size, min_max_line_size, rotate, num_of_mat, numb_of_picture, num_of_neurons)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-01-17T13:15:14.923173Z"
    }
   },
   "id": "e4b10037665fa737",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "batch_size = 2**8\n",
    "start_epochs = 20\n",
    "end_epochs = 5\n",
    "hyper_epochs = 20\n",
    "\n",
    "epochs_list = [round((-start_epochs+end_epochs)/(1+np.exp(-4*(x-hyper_epochs/5)))+start_epochs) for x in range(hyper_epochs)]\n",
    "\n",
    "start = time.time()\n",
    "for epochs in epochs_list:\n",
    "    matrix_lister.train_neural_network(batch_size=batch_size, num_epochs=epochs)\n",
    "    matrix_lister.make_new_matrix_in_list(kernel_size=(2,2), num_of_mat=500)\n",
    "print(time.time() - start)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d3a3ba654f5578cd",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "ani = matrix_lister.plot_matrices(20)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8a89a8474ac359d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "    HTML(ani.to_html5_video())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1a818fccf14d58e4",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "2ef602068abccfca",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
