{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not running on CoLab\n"
     ]
    }
   ],
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "  print('Running on CoLab')\n",
    "  %matplotlib inline\n",
    "else:\n",
    "    print('Not running on CoLab')\n",
    "    %matplotlib notebook\n",
    "    import os\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-17T13:16:25.531034700Z",
     "start_time": "2024-01-17T13:16:25.234148500Z"
    }
   },
   "id": "2e97eb7cabcc0430",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import scipy as sp\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, GRU, Conv2D, Flatten, MaxPooling2D, Dropout, Reshape, TimeDistributed\n",
    "from keras.metrics import F1Score\n",
    "from IPython.display import HTML\n",
    "from funtion_file import matrix_maker\n",
    "\n",
    "class MatrixMaker:\n",
    "    __slots__ = (\"rows\", \"cols\", \"kernel_size\", \"line_size\", 'num_per_mat', 'smooth_matrix', 'line_start_position', 'alfa', 'matrix_fade', 'line_pos_mat')\n",
    "    def __init__(self, rows, cols=None, kernel_size=(1, 1), line_size=(1, 2), num_per_mat=10):\n",
    "        self.rows = rows\n",
    "        self.cols = cols or rows\n",
    "        self.kernel_size = kernel_size\n",
    "        self.line_size = line_size\n",
    "        self.num_per_mat = num_per_mat\n",
    "\n",
    "        self.smooth_matrix = self.create_smoothed_matrix()\n",
    "        self.line_start_position = self.create_line_start_position()\n",
    "        self.alfa = self.create_alfa()\n",
    "        self.matrix_fade = self.create_matrix_line_fade()\n",
    "        self.line_pos_mat = self.create_line_pos_mat()\n",
    "\n",
    "    def create_smoothed_matrix(self):\n",
    "        kernel = np.ones(shape=self.kernel_size, dtype=float) / (self.kernel_size[0] * self.kernel_size[1])\n",
    "        return sp.ndimage.convolve(np.random.rand(self.rows, self.cols), kernel)\n",
    "\n",
    "    def create_line_start_position(self):\n",
    "        return (np.random.randint(low=0, high=self.rows - self.line_size[0] + 1),\n",
    "                np.random.randint(low=0, high=self.cols - self.line_size[1] + 1))\n",
    "\n",
    "    def create_alfa(self):\n",
    "        return np.linspace(1, 0, num=self.num_per_mat)\n",
    "\n",
    "    def create_matrix_with_line(self, alfa):\n",
    "        matrix = np.ones((self.rows, self.cols))\n",
    "        matrix[self.line_start_position[0]:self.line_start_position[0] + self.line_size[0],\n",
    "        self.line_start_position[1]:self.line_start_position[1] + self.line_size[1]] = alfa\n",
    "        return matrix\n",
    "\n",
    "    def create_matrix_line_fade(self):\n",
    "        matrix_line_fade = []\n",
    "        for i in range(self.num_per_mat):\n",
    "            line = self.create_matrix_with_line(self.alfa[i])\n",
    "            matrix_line_fade.append(self.smooth_matrix * line)\n",
    "\n",
    "        return matrix_line_fade\n",
    "\n",
    "    def create_line_pos_mat(self):\n",
    "        return np.array(np.logical_not(self.create_matrix_with_line(0)).astype(int), dtype='float16')\n",
    "\n",
    "\n",
    "class MatrixLister:\n",
    "    def __init__(self, row_len, col_len, kernel_size, min_max_line_size, rotate, num_of_mat, num_per_mat, num_neuron):\n",
    "        self.row_len = row_len\n",
    "        self.col_len = col_len\n",
    "        self.kernel_size = kernel_size\n",
    "        self.min_max_line_size = min_max_line_size\n",
    "        self.rotate = rotate\n",
    "        self.num_of_mat = num_of_mat\n",
    "        self.num_per_mat = num_per_mat\n",
    "        self.num_neuron = num_of_neurons\n",
    "\n",
    "        self.matrix_list = self.create_matrix_in_list()\n",
    "        self.con_matrix, self.con_alfa = self.concatenate_matrices()\n",
    "\n",
    "        self.neural_network = NeuralNetwork(input_size=(row_len, col_len), num_neuron=self.num_neuron)\n",
    "\n",
    "    def create_matrix_in_list(self):\n",
    "        line_sizes = [rotater((np.random.randint(self.min_max_line_size[0][0], self.min_max_line_size[1][0] + 1),\n",
    "                       np.random.randint(self.min_max_line_size[0][1], self.min_max_line_size[1][1] + 1)))\n",
    "                      for _ in range(self.num_of_mat)]\n",
    "\n",
    "        return [MatrixMaker(self.row_len, self.col_len, self.kernel_size, line_sizes[i], self.num_per_mat)\n",
    "                for i in range(self.num_of_mat)]\n",
    "\n",
    "    def concatenate_matrices(self):\n",
    "        concatenated_matrices = []\n",
    "        con_alfa = []\n",
    "\n",
    "        for matrix in self.matrix_list:\n",
    "            concatenated_matrices += matrix.create_matrix_line_fade()\n",
    "            con_alfa += list(matrix.alfa)\n",
    "\n",
    "        return np.array(concatenated_matrices, dtype='float32'), con_alfa\n",
    "\n",
    "    def con_line_pos_mat(self):\n",
    "        con_line_pos_mat = []\n",
    "        for matrix in self.matrix_list:\n",
    "            for alfa in matrix.alfa:\n",
    "                if alfa != 1:\n",
    "                    con_line_pos_mat.append(matrix.line_pos_mat)\n",
    "                else:\n",
    "                    con_line_pos_mat.append(np.zeros((self.row_len, self.col_len)))\n",
    "                    \n",
    "                    \n",
    "        fisk = np.stack(con_line_pos_mat)\n",
    "        return fisk\n",
    "    \n",
    "    def make_new_matrix_in_list(self, **kwargs):\n",
    "        update = False\n",
    "        for key, value in kwargs.items():\n",
    "            if key in ['row_len', 'col_len']:\n",
    "                update = True\n",
    "            if hasattr(self, key):\n",
    "                setattr(self, key, value)\n",
    "            else:\n",
    "                print(f\"Attribute {key} does not exist in the class.\")\n",
    "        \n",
    "        self.matrix_list = self.create_matrix_in_list()\n",
    "        self.con_matrix, self.con_alfa = self.concatenate_matrices()\n",
    "        if update:\n",
    "            self.neural_network = NeuralNetwork(input_size=(row_len, col_len), num_neuron=self.num_neuron)\n",
    "\n",
    "    def train_neural_network(self, num_epochs=10, batch_size=64):\n",
    "\n",
    "        self.neural_network.train(self.con_matrix, self.con_line_pos_mat(), num_epochs, batch_size)\n",
    "\n",
    "    def plot(self, interval=200):\n",
    "        fig, ax = plt.subplots()\n",
    "\n",
    "        def update(frame):\n",
    "            ax.clear()\n",
    "            im = ax.imshow(self.con_matrix[frame], interpolation='nearest', aspect='auto', vmin=0, vmax=1)\n",
    "\n",
    "            return [im]\n",
    "\n",
    "        animation = FuncAnimation(fig, update, frames=len(self.con_matrix), interval=interval, repeat=False, blit=True)\n",
    "        plt.tight_layout()\n",
    "        plt.show(block=False)\n",
    "        plt.show()\n",
    "        return animation\n",
    "    \n",
    "    def plot_matrices(self, num_to_pred, new_mat=False, interval=500):\n",
    "        if new_mat:\n",
    "            self.num_of_mat = num_to_pred\n",
    "            self.matrix_list = self.create_matrix_in_list()\n",
    "            self.con_matrix, self.con_alfa = self.concatenate_matrices()\n",
    "            \n",
    "        input_matrix = np.array(self.con_matrix[:num_to_pred*self.num_per_mat])\n",
    "        true_matrix = np.array(self.con_line_pos_mat())\n",
    "        pred = self.neural_network.predict(input_matrix)\n",
    "    \n",
    "        predicted_line_pos_mat = np.array(pred).reshape(input_matrix.shape)\n",
    "        \n",
    "        fig, axes = plt.subplots(1, 3, figsize=(12, 4))  # 1 row, 3 columns\n",
    "    \n",
    "        def update(frame):\n",
    "            # Plot Input Matrix\n",
    "            im = [axes[0].imshow(input_matrix[frame], interpolation='nearest', aspect='auto', vmin=0, vmax=1)]\n",
    "            axes[0].set_title('Input Matrix')\n",
    "    \n",
    "            # Plot True Line Position Matrix\n",
    "            im.append(axes[1].imshow(true_matrix[frame], interpolation='nearest', aspect='auto', vmin=0, vmax=1))\n",
    "            axes[1].set_title('True Line Position Matrix')\n",
    "    \n",
    "            # Plot Predicted Line Position Matrix\n",
    "            im.append(axes[2].imshow(predicted_line_pos_mat[frame], interpolation='nearest', aspect='auto', vmin=0, vmax=1))\n",
    "            axes[2].set_title('Predicted Line Position Matrix')\n",
    "            \n",
    "            return im\n",
    "    \n",
    "        animation = FuncAnimation(fig, update, frames=len(input_matrix), interval=interval, repeat=False, blit=True)\n",
    "    \n",
    "        plt.tight_layout()\n",
    "        plt.show(block=False)\n",
    "        return animation\n",
    "\n",
    "\n",
    "def rotater(line):\n",
    "    if np.random.random() < 0.5:\n",
    "        return line[::-1]\n",
    "    return line\n",
    "\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, input_size, num_neuron):\n",
    "        self.fh = None \n",
    "        self.model = self.build_model(input_size, num_neuron)\n",
    "\n",
    "    def build_model(self, input_size, num_neuron):\n",
    "        model = Sequential()\n",
    "        \n",
    "        # Apply Conv2D and Flatten to each time step\n",
    "        model.add(Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "        model.add(Conv2D(64, kernel_size=(2, 2), padding='same', activation='relu'))\n",
    "        model.add(MaxPooling2D(pool_size=2))\n",
    "        model.add(Conv2D(128, kernel_size=(2, 2), padding='same', activation='relu'))\n",
    "        model.add(MaxPooling2D(pool_size=2))\n",
    "        # Apply SimpleRNN to the output of Conv2D and Flatten\n",
    "        model.add(TimeDistributed(Flatten()))\n",
    "        model.add(GRU(num_neuron, activation='tanh', return_sequences=True))\n",
    "        model.add(Dropout(0.1))\n",
    "        model.add(GRU(num_neuron, activation='tanh'))\n",
    "        \n",
    "        # Fully connected layer\n",
    "        model.add(Dense(input_size[0] * input_size[1], activation='sigmoid'))\n",
    "        \n",
    "        # Reshape to the desired output shape\n",
    "        model.add(Reshape((input_size[0], input_size[1], 1)))\n",
    "        \n",
    "        model.compile(optimizer='adam', loss='KLDvi', metrics=['binary_accuracy'])\n",
    "        return model\n",
    "\n",
    "    def train(self, input_data, output_data, epochs, batch_size):\n",
    "        in_data = np.expand_dims(input_data, -1)\n",
    "        out_data = np.expand_dims(output_data, -1)\n",
    "\n",
    "        self.model.fit(in_data, out_data, epochs=epochs, batch_size=batch_size)\n",
    "\n",
    "    def predict(self, input_matrices):\n",
    "        # Flatten and concatenate all input matrices in the batch\n",
    "        input_data = np.expand_dims(np.array([matrix for matrix in input_matrices]),-1)\n",
    "    \n",
    "        # Predict the output for the entire batch\n",
    "        predicted_output = self.model.predict(input_data)\n",
    "    \n",
    "        return predicted_output\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-17T13:29:25.321204Z",
     "start_time": "2024-01-17T13:29:25.288402100Z"
    }
   },
   "id": "e60586cf65efb97b",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "row_len = 10\n",
    "col_len = 12\n",
    "kernel_size = (3, 3)\n",
    "min_max_line_size = [(1,4),(2,5)]\n",
    "rotate = True\n",
    "num_of_mat = 500\n",
    "numb_of_picture = 8\n",
    "num_of_neurons = 256\n",
    "\n",
    "matrix_lister = MatrixLister(row_len, col_len, kernel_size, min_max_line_size, rotate, num_of_mat, numb_of_picture, num_of_neurons)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-17T13:29:25.946218300Z",
     "start_time": "2024-01-17T13:29:25.886220300Z"
    }
   },
   "id": "e4b10037665fa737",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Work program\\python\\Masterfil\\pythonProject1\\.venv\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Work program\\python\\Masterfil\\pythonProject1\\.venv\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Work program\\python\\Masterfil\\pythonProject1\\.venv\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Work program\\python\\Masterfil\\pythonProject1\\.venv\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1151, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Work program\\python\\Masterfil\\pythonProject1\\.venv\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1209, in compute_loss\n        return self.compiled_loss(\n    File \"C:\\Work program\\python\\Masterfil\\pythonProject1\\.venv\\lib\\site-packages\\keras\\src\\engine\\compile_utils.py\", line 252, in __call__\n        self.build(y_pred)\n    File \"C:\\Work program\\python\\Masterfil\\pythonProject1\\.venv\\lib\\site-packages\\keras\\src\\engine\\compile_utils.py\", line 194, in build\n        self._losses = tf.nest.map_structure(\n    File \"C:\\Work program\\python\\Masterfil\\pythonProject1\\.venv\\lib\\site-packages\\keras\\src\\engine\\compile_utils.py\", line 365, in _get_loss_object\n        loss = losses_mod.get(loss)\n    File \"C:\\Work program\\python\\Masterfil\\pythonProject1\\.venv\\lib\\site-packages\\keras\\src\\losses.py\", line 2965, in get\n        return deserialize(identifier, use_legacy_format=use_legacy_format)\n    File \"C:\\Work program\\python\\Masterfil\\pythonProject1\\.venv\\lib\\site-packages\\keras\\src\\losses.py\", line 2912, in deserialize\n        return legacy_serialization.deserialize_keras_object(\n    File \"C:\\Work program\\python\\Masterfil\\pythonProject1\\.venv\\lib\\site-packages\\keras\\src\\saving\\legacy\\serialization.py\", line 537, in deserialize_keras_object\n        raise ValueError(\n\n    ValueError: Unknown loss function: 'logarytmic'. Please ensure you are using a `keras.utils.custom_object_scope` and that this object is included in the scope. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details.\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[12], line 10\u001B[0m\n\u001B[0;32m      8\u001B[0m start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epochs \u001B[38;5;129;01min\u001B[39;00m epochs_list:\n\u001B[1;32m---> 10\u001B[0m     \u001B[43mmatrix_lister\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_neural_network\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_epochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mepochs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     11\u001B[0m     matrix_lister\u001B[38;5;241m.\u001B[39mmake_new_matrix_in_list(kernel_size\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m2\u001B[39m,\u001B[38;5;241m2\u001B[39m), num_of_mat\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m500\u001B[39m)\n\u001B[0;32m     12\u001B[0m \u001B[38;5;28mprint\u001B[39m(time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m-\u001B[39m start)\n",
      "Cell \u001B[1;32mIn[10], line 122\u001B[0m, in \u001B[0;36mMatrixLister.train_neural_network\u001B[1;34m(self, num_epochs, batch_size)\u001B[0m\n\u001B[0;32m    120\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtrain_neural_network\u001B[39m(\u001B[38;5;28mself\u001B[39m, num_epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m, batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m64\u001B[39m):\n\u001B[1;32m--> 122\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mneural_network\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcon_matrix\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcon_line_pos_mat\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_epochs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[10], line 214\u001B[0m, in \u001B[0;36mNeuralNetwork.train\u001B[1;34m(self, input_data, output_data, epochs, batch_size)\u001B[0m\n\u001B[0;32m    211\u001B[0m in_data \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mexpand_dims(input_data, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m    212\u001B[0m out_data \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mexpand_dims(output_data, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m--> 214\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43min_data\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mout_data\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mepochs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\Work program\\python\\Masterfil\\pythonProject1\\.venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[0;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[1;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file1b4jzv5z.py:15\u001B[0m, in \u001B[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001B[1;34m(iterator)\u001B[0m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     14\u001B[0m     do_return \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m---> 15\u001B[0m     retval_ \u001B[38;5;241m=\u001B[39m ag__\u001B[38;5;241m.\u001B[39mconverted_call(ag__\u001B[38;5;241m.\u001B[39mld(step_function), (ag__\u001B[38;5;241m.\u001B[39mld(\u001B[38;5;28mself\u001B[39m), ag__\u001B[38;5;241m.\u001B[39mld(iterator)), \u001B[38;5;28;01mNone\u001B[39;00m, fscope)\n\u001B[0;32m     16\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m:\n\u001B[0;32m     17\u001B[0m     do_return \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "\u001B[1;31mValueError\u001B[0m: in user code:\n\n    File \"C:\\Work program\\python\\Masterfil\\pythonProject1\\.venv\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Work program\\python\\Masterfil\\pythonProject1\\.venv\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Work program\\python\\Masterfil\\pythonProject1\\.venv\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Work program\\python\\Masterfil\\pythonProject1\\.venv\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1151, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Work program\\python\\Masterfil\\pythonProject1\\.venv\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1209, in compute_loss\n        return self.compiled_loss(\n    File \"C:\\Work program\\python\\Masterfil\\pythonProject1\\.venv\\lib\\site-packages\\keras\\src\\engine\\compile_utils.py\", line 252, in __call__\n        self.build(y_pred)\n    File \"C:\\Work program\\python\\Masterfil\\pythonProject1\\.venv\\lib\\site-packages\\keras\\src\\engine\\compile_utils.py\", line 194, in build\n        self._losses = tf.nest.map_structure(\n    File \"C:\\Work program\\python\\Masterfil\\pythonProject1\\.venv\\lib\\site-packages\\keras\\src\\engine\\compile_utils.py\", line 365, in _get_loss_object\n        loss = losses_mod.get(loss)\n    File \"C:\\Work program\\python\\Masterfil\\pythonProject1\\.venv\\lib\\site-packages\\keras\\src\\losses.py\", line 2965, in get\n        return deserialize(identifier, use_legacy_format=use_legacy_format)\n    File \"C:\\Work program\\python\\Masterfil\\pythonProject1\\.venv\\lib\\site-packages\\keras\\src\\losses.py\", line 2912, in deserialize\n        return legacy_serialization.deserialize_keras_object(\n    File \"C:\\Work program\\python\\Masterfil\\pythonProject1\\.venv\\lib\\site-packages\\keras\\src\\saving\\legacy\\serialization.py\", line 537, in deserialize_keras_object\n        raise ValueError(\n\n    ValueError: Unknown loss function: 'logarytmic'. Please ensure you are using a `keras.utils.custom_object_scope` and that this object is included in the scope. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 2**8\n",
    "start_epochs = 20\n",
    "end_epochs = 5\n",
    "hyper_epochs = 20\n",
    "\n",
    "epochs_list = [round((-start_epochs+end_epochs)/(1+np.exp(-4*(x-hyper_epochs/5)))+start_epochs) for x in range(hyper_epochs)]\n",
    "\n",
    "start = time.time()\n",
    "for epochs in epochs_list:\n",
    "    matrix_lister.train_neural_network(batch_size=batch_size, num_epochs=epochs)\n",
    "    matrix_lister.make_new_matrix_in_list(kernel_size=(2,2), num_of_mat=500)\n",
    "print(time.time() - start)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-17T13:29:27.664740900Z",
     "start_time": "2024-01-17T13:29:26.965624200Z"
    }
   },
   "id": "d3a3ba654f5578cd",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "ani = matrix_lister.plot_matrices(20)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-17T13:16:29.186997100Z",
     "start_time": "2024-01-17T13:16:29.183010500Z"
    }
   },
   "id": "8a89a8474ac359d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "    HTML(ani.to_html5_video())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-17T13:16:29.184007300Z"
    }
   },
   "id": "1a818fccf14d58e4",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-17T13:16:29.185004Z"
    }
   },
   "id": "2ef602068abccfca",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
